
ML Concepts

Framing
---------------------
Frame a task as a ML problem, basic vocabulary.

Learning Objectives
Refresh the fundamental ML terms.
Explore various uses of ML.
Explore the key terminology of ML in the following short video (2 min).

- Supervised ML systems learn how to combine input to produce useful predictions on never-before-seen data.

* Labels Y
  - A label is the thing we're predicting. The y variable in simple linear regression. Y to the sky. 
  - The label could be the future price of wheat, the kind of animal shown in a picture, 
    the meaning of an audio clip, or just about anything.

* Features X
  - A feature is an input variable. The x variable in simple linear regression. 
  - A simple ML project might use a single feature, while a more sophisticated ML project could use millions of features,
    specified as: {x1,x2,...xN}
  - In the spam detector example, the features could include the following:
    - words in the email text
    - sender's address
    - time of day the email was sent
    - email contains the phrase "one weird trick."

* Examples X
  - An example is an instance of data, x (a vector). 
    - labeled examples
      - includes both feature(s) and the label 
      - labledExample = {features, label}: (x, y)
      - Used to train the model (such as individual emails that users have marked as "spam" or "not spam").
    - unlabeled examples
      - Contains features but, not the label.
      - unlabeledExample = {features, ?}: (x, ?)
      - Once model is trained with labeled examples, we use that model to predict the label on the unlabeled examples. 
        (such as new emails that humans haven't yet labeled).

* Models
  - Defines the relationship between features and label. 
  - In lin regression, it's just the line :)
  - A model consists of a set of weights and a bias ||| y = wx + b |||
  - e.g. spam detection model might associate certain features strongly with "spam". 
  - ||| Inference ||| means applying the trained model to unlabeled examples, to infer. 
  - So use the trained model to make useful predictions (y'). 
  - For example, during inference, you can predict spam given new unlabeled examples.

* Regression vs. classification an what they predict
 - Regression model predicts continuous values [RC].
 - Classification model predicts discrete values [CD]. 
 
 - Regression models make predictions:
  - What is the value of a house in California?
  - What is the probability that a user will click on this ad?
 - Classification models make predictions;
  - Is a given email message spam or not spam?
  - Is this an image of a dog, a cat, or a hamster?
  
* Loss
  - Models are composed of weights and biases, which are learned from a set of examples.
  - Loss is a number measuring how bad a model's predictions are. Good models typically have less loss than bad ones.
  - Squared hence always positive and so to amplify values far from the line.

* Supervised Learning
 - Some labels might be untrustworthy.
 - unlabeled examples are the ones to test.
